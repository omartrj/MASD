services:

  # === KAFKA CLUSTER ===
  # 3 broker Kafka con Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    hostname: zookeeper
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - masd-network

  kafka1:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka1
    container_name: kafka1
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092
      KAFKA_NUM_PARTITIONS: ${KAFKA_NUM_PARTITIONS}
      KAFKA_DEFAULT_REPLICATION_FACTOR: ${KAFKA_DEFAULT_REPLICATION_FACTOR}
      KAFKA_MIN_INSYNC_REPLICAS: ${KAFKA_MIN_INSYNC_REPLICAS}
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR}
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9092"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - masd-network

  kafka2:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka2
    container_name: kafka2
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9093
      KAFKA_NUM_PARTITIONS: ${KAFKA_NUM_PARTITIONS}
      KAFKA_DEFAULT_REPLICATION_FACTOR: ${KAFKA_DEFAULT_REPLICATION_FACTOR}
      KAFKA_MIN_INSYNC_REPLICAS: ${KAFKA_MIN_INSYNC_REPLICAS}
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR}
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9093"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - masd-network

  kafka3:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka3
    container_name: kafka3
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9094
      KAFKA_NUM_PARTITIONS: ${KAFKA_NUM_PARTITIONS}
      KAFKA_DEFAULT_REPLICATION_FACTOR: ${KAFKA_DEFAULT_REPLICATION_FACTOR}
      KAFKA_MIN_INSYNC_REPLICAS: ${KAFKA_MIN_INSYNC_REPLICAS}
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR}
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9094"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - masd-network

  # === KAFKA UI ===
  # Per avviare: docker-compose --profile kafka-ui up -d 
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    profiles:
      - kafka-ui
    depends_on:
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      kafka3:
        condition: service_healthy
    ports:
      - 8080:8080
    environment:
      KAFKA_CLUSTERS_0_NAME: masd-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:9092,kafka2:9093,kafka3:9094
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    networks:
      - masd-network

  # === HADOOP CLUSTER ===
  # I container hadoop usano un file di configurazione in formato KEY=VALUE
  # ricavato dalla guida ufficiale del container apache/hadoop.
  # https://hub.docker.com/r/apache/hadoop
  # Datanode scalabili usando --scale hdfs-datanode=n
  hdfs-namenode:
    image: apache/hadoop:3
    hostname: namenode
    container_name: hdfs-namenode
    command: ["hdfs", "namenode"]
    ports:
      - 9870:9870
    volumes:
      - hadoop-config:${HADOOP_HOME}/etc/hadoop
    env_file:
      - ./hadoop.config
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
    networks:
      - masd-network
  
  hdfs-datanode:
    image: apache/hadoop:3
    command: ["hdfs", "datanode"]
    env_file:
      - ./hadoop.config
    volumes:
      - hadoop-config:${HADOOP_HOME}/etc/hadoop
    networks:
      - masd-network
  
  # === YARN CLUSTER ===
  # Nodemanager scalabili usando --scale yarn-nodemanager=n
  yarn-resourcemanager:
    image: apache/hadoop:3
    hostname: resourcemanager
    container_name: yarn-resourcemanager
    command: ["yarn", "resourcemanager"]
    ports:
      - 8088:8088
    env_file:
      - ./hadoop.config
    volumes:
      - hadoop-config:${HADOOP_HOME}/etc/hadoop
    networks:
      - masd-network
  
  yarn-nodemanager:
    image: apache/hadoop:3
    command: ["yarn", "nodemanager"]
    env_file:
      - ./hadoop.config
    volumes:
      - hadoop-config:${HADOOP_HOME}/etc/hadoop
    networks:
      - masd-network

  # === SPARK APPLICATION ===
  spark-app:
    build:
      context: ./spark-app
      dockerfile: Dockerfile
    container_name: spark-app
    hostname: spark-app
    ports:
      - 4040:4040
    depends_on:
      yarn-resourcemanager:
        condition: service_started
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      kafka3:
        condition: service_healthy
      mongodb:
        condition: service_started
    environment:
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      - YARN_CONF_DIR=/opt/hadoop/etc/hadoop
      - HADOOP_USER_NAME=hadoop
      - PROJECT_NAME=${PROJECT_NAME}
      - PROJECT_VERSION=${VERSION}
      - PROJECT_AUTHOR=${AUTHOR}
      - PROJECT_EMAIL=${EMAIL}
      - PROJECT_GITHUB=${GITHUB_REPO}
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - KAFKA_TOPIC_PREFIX=${KAFKA_TOPIC_PREFIX}
      - MONGO_URI=${MONGO_URI}
      - MONGO_DATABASE=${MONGO_DATABASE}
      - SPARK_AGGREGATE_TRIGGER_INTERVAL=${SPARK_AGGREGATE_TRIGGER_INTERVAL}
      - SPARK_AGGREGATE_WINDOW=${SPARK_AGGREGATE_WINDOW}
      - SPARK_AGGREGATE_SLIDE=${SPARK_AGGREGATE_SLIDE}
      - SPARK_AGGREGATE_WATERMARK=${SPARK_AGGREGATE_WATERMARK}
      - SPARK_AGGREGATE_CHECKPOINT_DIR=${SPARK_AGGREGATE_CHECKPOINT_DIR}
    volumes:
      - hadoop-config:/opt/hadoop/etc/hadoop # <-- Usa i file di configurazione generati dai container hadoop
    command: >
      /opt/spark/bin/spark-submit
      --master local[*]
      --deploy-mode client
      --conf "spark.driver.extraJavaOptions=-Divy.home=/opt/spark/.ivy2 -Djava.io.tmpdir=/opt/spark/tmp"
      --packages org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.1,org.mongodb.spark:mongo-spark-connector_2.13:10.5.0
      /opt/spark/work-dir/consumer.py
    healthcheck:
      test: ["CMD", "test", "-f", "/tmp/spark-ready"]
      interval: 5s
      timeout: 3s
      retries: 60
      start_period: 10s
    networks:
      - masd-network

  # === MONGODB DATABASE ===
  mongodb:
    image: mongo:8.2
    container_name: mongodb
    volumes:
      - mongo-data:/data/db
    networks:
      - masd-network

  # === MONGODB UI ===
  # Per avviare: docker-compose --profile mongo-ui up -d
  mongo-express:
    image: mongo-express:latest
    container_name: mongo-express
    profiles:
      - mongo-ui
    depends_on:
      - mongodb
    ports:
      - 8081:8081
    environment:
      ME_CONFIG_MONGODB_URL: ${MONGO_URI}
      ME_CONFIG_BASICAUTH: false
    networks:
      - masd-network

volumes:
  # I container apache/hadoop generano le configurazioni xml a partire da un file in formato
  # KEY=VALUE. I container apache/spark invece si aspettano di trovare i file xml direttamente.
  # Per questo motivo uso questo volume per condividere i file di configurazione generati tra i container hadoop e spark.
  hadoop-config:
    name: hadoop-config
  mongo-data:
    name: mongo-data

networks:
  masd-network:
    name: masd-network
    driver: bridge
